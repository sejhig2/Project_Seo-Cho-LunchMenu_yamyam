{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "네이버지도v4크롤링 - 윤혜수",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNpn+dBQAjromLxlZSzDPKX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sejhig2/Project_Seo-Cho-LunchMenu_yamyam/blob/main/%EB%84%A4%EC%9D%B4%EB%B2%84%EC%A7%80%EB%8F%84v4%ED%81%AC%EB%A1%A4%EB%A7%81_%EC%9C%A4%ED%98%9C%EC%88%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKZc6h0xeVQj"
      },
      "source": [
        "#네이버지도v4크롤링\n",
        "##### 엑셀저장 전 전처리 크롤링1(주피터검퓨터ver) #####\n",
        "## 전처리1-1 식당상호명,식당url,이미지url 크롤링하기 ##\n",
        "\n",
        "# 라이브러리 불러오기\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import time\n",
        "driver = webdriver.Chrome(\"c:/chromedriver.exe\")\n",
        "\n",
        "# 네이버지도v4 창열기\n",
        "url =\"https://v4.map.naver.com\"\n",
        "driver.get(url)\n",
        "driver.find_elements_by_css_selector(\"button.btn_close\")[1].click()\n",
        "search_box = driver.find_element_by_css_selector(\"input#search-input\")\n",
        "\n",
        "# 네이버지도v4에서 식당검색\n",
        "# 검색할 식당 리스트 생성(내용 바꿀 수 있음ex.남부터미널역 한식 맛집)\n",
        "list = [\"효령로 한식 맛집\",\"효령로 양식 맛집\",\"효령로 일식 맛집\",\"효령로 중식 맛집\",\"효령로 분식 맛집\"]\n",
        "# for구문을 이용하여 list 요소들을 하나씩 검색하기\n",
        "for a in list:\n",
        "    search_box.send_keys(a)\n",
        "    search_button = driver.find_element_by_css_selector(\"button.spm\")\n",
        "    search_button.click()\n",
        "    print(\"----------\"+a+\"----------\") # 다음 식당을 크롤링 할때 가독성을 위한 구분선\n",
        "    \n",
        "    # 다음페이지 넘기기 범위\n",
        "    for b in range(2,6):\n",
        "        stores = driver.find_elements_by_css_selector(\"div.lsnx\")\n",
        "        \n",
        "        \n",
        "        # 식당상호명,url,이미지 범위 찾기\n",
        "        for store in stores:\n",
        "            name = store.find_element_by_css_selector(\"dt > a\").text # 식당상호명\n",
        "            siteview = store.find_element_by_css_selector(\"span.ico\") # 식당url정보가 들어있는 범위\n",
        "            siteview_text = siteview.text # text로 변환\n",
        "            image = store.find_element_by_css_selector(\"div > img\") # 이미지url\n",
        "            \n",
        "            # 식당상호명,url,이미지 추출\n",
        "            try:\n",
        "                a_tag = siteview.find_element_by_css_selector(\"div.lsnx > dl > dt > span > a\") # 식당 url이 들어있는 태그\n",
        "                href = a_tag.get_attribute('href') # href값 추출\n",
        "                src = image.get_attribute('src') # 이미지가 들어있는 src값 추출\n",
        "                if \"가격\" in siteview_text: \n",
        "                    print(name,\"url: \"+href,\"image: \"+src,sep=\" / \") \n",
        "                if \"가격\" not in siteview_text:\n",
        "                    print(name,\"None\") \n",
        "            except: \n",
        "                print(name,\"주소없음\") \n",
        "        \n",
        "        # 다음페이지 넘기기 클릭\n",
        "        try:\n",
        "            page_bar = driver.find_elements_by_css_selector(\"div.paginate > *\") # 다음페이지 버튼\n",
        "            if b%5 !=0: \n",
        "                page_bar[b].click() \n",
        "                time.sleep(1)\n",
        "        except: \n",
        "            break\n",
        "            \n",
        "            \n",
        "    search_box.clear() # 다음 식당검색을 위해 검색창 초기화\n",
        "\t\n",
        "\t\n",
        "##### 엑셀저장전 전처리 크롤링2(주피터컴퓨터ver) #####\n",
        "## 전처리1-2 식당정보,리뷰,별점 크롤링(전처리1-1 식당url을 활용) ##\n",
        "\n",
        "# 라이브러리 불러오기\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import time\n",
        "driver = webdriver.Chrome(\"c:/chromedriver.exe\")\n",
        "\n",
        "# 전처리1-1에서 크롤링한 식당url을 활용하여 식당상세 페이지 들어가기\n",
        "url1 = \"https://store.naver.com/restaurants/detail?id=\" # 네이버플레이스 주소\n",
        "url2 = \"11819292\" # 식당 고유번호\n",
        "driver.get(url1 + url2) # 고유번호에 해당하는 식당상세페이지\n",
        "\n",
        "# 리뷰페이지 클릭\n",
        "driver.find_element_by_css_selector(\"div.sc_box a.btn_sc_more\").click()\n",
        "\n",
        "# 식당상호명,주소,카테고리 크롤링(전처리1-1의 결과와 병합하기 위해 식당상호명 다시 크롤링함)\n",
        "name = driver.find_element_by_css_selector(\"strong.name\").text # 식당상호명\n",
        "add = driver.find_element_by_css_selector(\"span.addr\").text # 식당주소\n",
        "cate = driver.find_element_by_css_selector(\"span.category\").text # 식당카테고리(ex.한식)\n",
        "print(name,add,cate,sep=' / ')\n",
        "\n",
        "# 별점 크롤링\n",
        "star_list = driver.find_elements_by_css_selector(\"span.score\") # 별점데이터를 갖고있는 범위 찾기\n",
        "for star in star_list: # 찾은 별점데이터들의 요소들을 하나씩 꺼내기\n",
        "    star_text = star.text # 각 별점데이터 요소들을 text화\n",
        "    print(\"별점 :\"+star_text) # text화된 별점값 출력\n",
        "    \n",
        "# 리뷰 크롤링\n",
        "review_list = driver.find_elements_by_css_selector(\"div.review_txt\") # 리뷰데이터를 갖고있는 범위 찾기\n",
        "for review in review_list: # 찾은 리뷰데이터들의 요소들을 하나씩 꺼내기\n",
        "    review_text = review.text # 각 리뷰데이터 요소들을 text화\n",
        "    print(\"리뷰 :\"+review_text) # text화된 리뷰값 출력"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}